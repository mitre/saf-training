---
order: 15
next: 16.md
title: Demo - Finalizing the Mapper
author: Charles Hu
---

WORKING TO REFACTOR FOLLOWING SECTION

[placeholder]

7. Set up and use regression testing on your mapper.

  - 7a. Uncomment out the commented out lines in the <i>{YOUR-SAMPLE-EXPORT}-hdf.json</i> file created in step 4f. This will allow the regression tests to automatically generate a HDF output file whenever you run the tests. The commented out lines should look similar to the following:

    ```
    // fs.writeFileSync(
    //   'sample_jsons/skeleton_mapper/skeleton-hdf.json',
    //   JSON.stringify(mapper.toHdf(), null, 2)
    // );
    ```

  - 7b. Using the terminal, cd into the <i>hdf-converters</i> directory and run the following command. This command will run your mapper against the sample export file in <i>sample_jsons</i> and test to see if the output is generated as expected.

    ```
    yarn run test --verbose --silent=false ./test/mappers/forward/{YOUR-EXPORT-NAME-HERE}_mapper.spec.ts
    ```
  
  - 7c. Your tests should generate HDF output files for when <i>--with-raw</i> is not flagged (default behavior) and when it is flagged (denoted by <i>-withraw</i> in the filename). It will also compare the contents of these generated files with a temporary mapper instance created in the test itself. Review the test output to ensure that the tests are all passing and review the HDF output files to ensure that the contents of the mapping are being generated correctly.

  - 7d. Recomment out the lines from step 7b.

8. Document your new mapper in the README for <i>hdf-converters</i> under the <i>Supported Formats</i> section. It should be formatted as follows:

```
{#}. [{YOUR-EXPORT-NAME-HERE}] - {MAPPER INPUT DESCRIPTION}
```

9. Commit your final changes and mark your pull request as 'ready for review'. You should request for a code review from members of the SAF team and edit your code as necessary. Once approved, your mapper will be merged into the main development branch and [scheduled for release](https://github.com/mitre/heimdall2/wiki/How-to-create-a-Heimdall2-release) as an officially supported conversion format for the HDF Converters.

10. Create a development branch against the [SAF CLI repository](https://github.com/mitre/saf) and create a draft pull request for your new branch.

11. Set up for SAF CLI mapper integration.
  
  - 11a. In the <i>package.json</i> file, update the versions of <i>@mitre/hdf-converters</i> and <i>@mitre/heimdall-lite</i> to the [latest release of Heimdall2](https://github.com/mitre/heimdall2/releases).

  - 11b. In the <i>src/commands/convert</i> directory, create a blank TypeScript file. It should be named:

    ```
    {YOUR-EXPORT-NAME-HERE}2hdf.ts
    ```

  - 11c. In the <i>test/sample_data</i> directory, create a directory named <i>{YOUR-EXPORT-NAME-HERE}</i>. Underneath it, create a directory named <i>sample_input_report</i>. The file structure should now look like this:

    ```
    +-- sample_data
    |   +-- {YOUR-EXPORT-NAME-HERE}
    |   |   +-- sample_input_report
    ```

  - 11d. Place your sample export under the <i>sample_input_report</i> directory. Your sample export should be genericized to avoid any leaking of sensitive information. Under the <i>{YOUR-EXPORT-NAME-HERE}</i> directory, place your output HDF files generated during the testing phase of step 7c. The file structure should now look like this:

    ```
    +-- sample_data
    |   +-- {YOUR-EXPORT-NAME-HERE}
    |   |   +-- sample_input_report
    |   |   |   +-- {YOUR-SAMPLE-EXPORT}
    |   |   +-- {YOUR-EXPORT-NAME-HERE}-hdf.json
    |   |   +-- {YOUR-EXPORT-NAME-HERE}-hdf-withraw.json
    ```

  - 11e. In the <i>test/commands/convert</i> directory, create a blank TypeScript file. It should be named:

    ```
    {YOUR-EXPORT-NAME-HERE}2hdf.test.ts
    ```

12. Integrate your mapper with the SAF CLI.

  - 12a. Insert the <b>[skeleton](#skeleton)</b> for integrating a HDF mapper with the SAF CLI. Replace names (<i>skeleton</i> by default) as necessary.

  - 12b. Insert the <b>[skeleton](#skeleton)</b> for a convert command test for the SAF CLI. Replace names (<i>skeleton</i> by default) as necessary.

  - 12c. Navigate to the <i>index.ts</i> file under the <i>src/commands/convert</i> directory. Import your mapper using the existing import block as follows:
  
    ```
    import {
      ASFFResults,
      ...
      {YOUR-MAPPER-CLASS-HERE}
      } from '@mitre/hdf-converters'
    ```
  
  - 12d. Under the switch block in the <i>getFlagsForInputFile</i> function, add your mapper class as it is defined in step 5d for fingerprinting for the generic convert command. If the convert command for your mapper has any additional flags beyond the standard <i>--input</i> and <i>--output</i> flags, return the entire flag block in the switch case. This is demonstrated as follows:
  
    ```
    switch (Convert.detectedType) {
      ...
      case {YOUR-EXPORT-SERVICE-NAME-HERE}:
        return {YOUR-CLI-CONVERT-CLASS}.flags  //Only add if special flags exist
      ...
        return {}
      }
    ```

13. Edit the README file to reflect your newly added conversion command under the <i>To HDF</i> section. It should be formatted as follows:

```
##### {YOUR-EXPORT-NAME-HERE} to HDF

\```
convert {YOUR-EXPORT-NAME-HERE}2hdf       Translate a {YOUR-EXPORT-NAME-HERE} results {EXPORT-TYPE} into
                                              a Heimdall Data Format JSON file

OPTIONS
  -i, --input=input          Input {EXPORT-TYPE} File
  -o, --output=output        Output HDF JSON File
  -w, --with-raw             Include raw input file in HDF JSON file

EXAMPLES
  saf convert {YOUR-EXPORT-NAME-HERE}2hdf -i {INPUT-NAME} -o output-hdf-name.json
\```
```

14. Commit your changes and mark your pull request as 'ready for review'. You should request for a code review from members of the SAF team and edit your code as necessary. Once approved, merged, and [released](https://github.com/mitre/saf/wiki/Creating-a-Release-of-the-SAF-CLI), your mapper will be callable using the SAF CLI.

[placeholder]
