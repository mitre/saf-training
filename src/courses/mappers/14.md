---
order: 14
next: 15.md
title: Implementing a Mapper
author: Charles Hu
---

## Mapper Introduction

::: note OHDF Converters Utilities
Special utilities from OHDF Converters are used here. [Refer here](./09.md) for a refresher on OHDF Converters.
:::

Now that we have developed a mapping, we can implement that mapping as a mapper which applies the mapping to any compatible file for a conversion to OHDF.

## File Set Up

A number of crucial files that support and provide the infrastructure needed for the *-to-OHDF mapper have to be set up first before we begin actual mapper development.

::: note Specialized Security Tools
This guide is geared for security tools that provide scan-based export data. If your security tool provides a specialized form of export data or is an API, contact the SAF team for further guidance.
:::

### Mapper File

First, we need to create the file that hosts the mapper and link to it so other files in OHDF Converters can access it.

1. Create a blank TypeScript file under the `src` directory in `hdf-converters`. It should be named:
```
{YOUR-EXPORT-NAME-HERE}-mapper.ts
```

2. Select the appropriate mapper skeleton (see below) for your export type. Place them in the file created in step 1. Replace names (`SKELETON` by default) as necessary.

::: details JSON Mapper Skeleton
```typescript
import {ExecJSON} from 'inspecjs';
import _ from 'lodash';
import {version as HeimdallToolsVersion} from '../package.json';
import {
  BaseConverter,
  ILookupPath,
  impactMapping,
  MappedTransform
} from './base-converter';

const IMPACT_MAPPING: Map<string, number> = new Map([
  ['critical', 0.9],
  ['high', 0.7],
  ['medium', 0.5],
  ['low', 0.3]
]);

export class SKELETONMapper extends BaseConverter {
  withRaw: boolean;

  mappings: MappedTransform<
    ExecJSON.Execution & {passthrough: unknown},
    ILookupPath
  > = {
    platform: {
      name: 'Heimdall Tools',
      release: HeimdallToolsVersion,
      target_id: null  //Insert data
    },
    version: HeimdallToolsVersion,
    statistics: {
      duration: null  //Insert data
    },
    profiles: [
      {
        name: '',              //Insert data
        title: null,           //Insert data
        maintainer: null,      //Insert data
        summary: null,         //Insert data
        license: null,         //Insert data
        copyright: null,       //Insert data
        copyright_email: null, //Insert data
        supports: [],          //Insert data
        attributes: [],        //Insert data
        depends: [],           //Insert data
        groups: [],            //Insert data
        status: 'loaded',      //Insert data
        controls: [
          {
            key: 'id',
            tags: {},             //Insert data
            descriptions: [],     //Insert data
            refs: [],             //Insert data
            source_location: {},  //Insert data
            title: null,          //Insert data
            id: '',               //Insert data
            desc: null,           //Insert data
            impact: 0,            //Insert data
            code: null,           //Insert data
            results: [
              {
                status: ExecJSON.ControlResultStatus.Failed,  //Insert data
                code_desc: '',                                //Insert data
                message: null,                                //Insert data
                run_time: null,                               //Insert data
                start_time: ''                                //Insert data
              }
            ]
          }
        ],
        sha256: ''
      }
    ],
    passthrough: {
      transformer: (data: Record<string, any>): Record<string, unknown> => {
        return {
          auxiliary_data: [{name: '', data: _.omit([])}],  //Insert service name and mapped fields to be removed
          ...(this.withRaw && {raw: data})
        };
      }
    }
  };
  constructor(exportJson: string, withRaw = false) {
    super(JSON.parse(exportJson), true);
    this.withRaw = withRaw
  }
}
```
:::

3. Export your mapper class created in the previous steps by specifying its export in the <i>index.ts</i> file. Add the following line:
```
export * from './src/{YOUR-EXPORT-NAME-HERE}-mapper';
```

### Sample File

Next, we need to add a sample file for the mapper to ingest when running unit tests on it.

1. Create a new directory named `{YOUR-EXPORT-NAME-HERE}_mapper` under the `sample_jsons` directory in `hdf-converters`. Create another directory named `sample_input_report` in the directory you just made. The directory structure should look like this:
```
+-- sample_jsons
|   +-- {YOUR-EXPORT-NAME-HERE}-mapper
|   |   +-- sample_input_report
```

2. Place your sample export under the `sample_input_report` directory. Your sample export should be genericized to avoid any leaking of sensitive information. The directory structure should now look like this:
```
+-- sample_jsons
|   +-- {YOUR-EXPORT-NAME-HERE}-mapper
|   |   +-- sample_input_report
|   |   |   +-- {YOUR-SAMPLE-EXPORT}
```

### Unit Testing

Now that we have a sample file, we can now add some unit tests which automatically test our mapper to ensure that it is producing readable and correct OHDF file outputs.

1. Create a blank TypeScript file under the `test/mappers/forward` directory in `hdf-converters`. It should be named:
```
{YOUR-EXPORT-NAME-HERE}_mapper.spec.ts
```

2. Select the appropriate mapper test skeleton (see below) for your export type. Place it in the file created in step 1. Replace names (`SKELETON` by default) as necessary.

::: details JSON Mapper Test Skeleton
```typescript
import fs from 'fs';
import {SKELETONMapper} from '../../../src/SKELETON-mapper';
import {omitVersions} from '../../utils';

describe('SKELETON_mapper', () => {
  it('Successfully converts SKELETON targeted at a local/cloned repository data', () => {
    const mapper = new SKELETONMapper(
      fs.readFileSync(
        'sample_jsons/SKELETON_mapper/sample_input_report/SKELETON.json',
        {encoding: 'utf-8'}
      )
    );

    // fs.writeFileSync(
    //   'sample_jsons/SKELETON_mapper/SKELETON-hdf.json',
    //   JSON.stringify(mapper.toHdf(), null, 2)
    // );

    expect(omitVersions(mapper.toHdf())).toEqual(
      omitVersions(
        JSON.parse(
          fs.readFileSync(
            'sample_jsons/SKELETON_mapper/SKELETON-hdf.json',
            {
              encoding: 'utf-8'
            }
          )
        )
      )
    );
  });
});

describe('SKELETON_mapper_withraw', () => {
  it('Successfully converts withraw flagged SKELETON targeted at a local/cloned repository data', () => {
    const mapper = new SKELETONMapper(
      fs.readFileSync(
        'sample_jsons/SKELETON_mapper/sample_input_report/SKELETON.json',
        {encoding: 'utf-8'}
      ),
      true
    );

    // fs.writeFileSync(
    //   'sample_jsons/SKELETON_mapper/SKELETON-hdf-withraw.json',
    //   JSON.stringify(mapper.toHdf(), null, 2)
    // );

    expect(omitVersions(mapper.toHdf())).toEqual(
      omitVersions(
        JSON.parse(
          fs.readFileSync(
            'sample_jsons/SKELETON_mapper/SKELETON-hdf-withraw.json',
            {
              encoding: 'utf-8'
            }
          )
        )
      )
    );
  });
});
```
:::

### Fingerprinting

OHDF Converters has a fingerprinting service that detects a security tool data format and automatically applies the correct mapper to convert it to OHDF. To enable this feature, we need to explicitly declare keywords unique to the security tool data format as follows:

1. Go to the file `report_intake.ts` under the `heimdall2/apps/frontend/src/store` directory.

2. Import your mapper file. You should be able to add the name of your mapper class to a pre-existing import statement pointing at `hdf-converters` as follows:
```typescript
import {
  ASFFResults as ASFFResultsMapper,
  BurpSuiteMapper,
  ...
  {YOUR-MAPPER-CLASS-HERE}
} from '@mitre/hdf-converters';
```

3. Instantiate your mapper class in the `convertToHdf` switch block. Add the following lines:
```typescript
case '{YOUR-EXPORT-SERVICE-NAME-HERE}':
  return new {YOUR-MAPPER-CLASS-HERE}(convertOptions.data).toHdf();
```

4. Navigate to the file `fingerprinting.ts` in the `src/utils` directory in `hdf-converters`. Add keywords that are unique to your sample export to the `fileTypeFingerprints` variable. It should be formatted as follows:
```typescript
export const fileTypeFingerprints = {
  asff: ['Findings', 'AwsAccountId', 'ProductArn'],
  ...
  {YOUR-EXPORT-SERVICE-NAME-HERE}: [{UNIQUE KEYWORDS AS STRINGS}]
};
```

## Mapper Implementation


