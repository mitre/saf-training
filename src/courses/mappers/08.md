---
order: 8
next: 09.md
title: Mapper Creation 2
author: Charles Hu
---

### \*-to-HDF Creation Guide <a name="guide"></a>

1. Fork/branch a development repository from the main [Heimdall2 GitHub repository](https://github.com/mitre/heimdall2).

   - SAF team developers have write access to the main repository and should [create a branch](https://docs.github.com/en/desktop/contributing-and-collaborating-using-github-desktop/making-changes-in-a-branch/managing-branches#creating-a-branch) on the primary development repository. Non-SAF team developers should instead [create a fork](https://docs.github.com/en/get-started/quickstart/fork-a-repo#forking-a-repository) of the main repository and create a development branch there.

2. Create a draft [pull request](https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/proposing-changes-to-your-work-with-pull-requests/creating-a-pull-request#creating-the-pull-request) for your development branch against the main repository branch.

3. Have a rough, high-level outline of how your export translates to the HDF. For an example of this process, refer to the <b>[HDF Schema Mapping Example Walkthrough](#example)</b> section.

4. Set up for \*-to-HDF mapper development.

  - 4a. Install the necessary dependencies for Heimdall2. Under the <i>heimdall2</i> directory, enter the following command in the terminal:

    ```
    yarn install
    ```

  - 4b. Create a blank TypeScript file under the <i>src</i> directory in <i>hdf-converters</i>. It should be named:

    ```
    {YOUR-EXPORT-NAME-HERE}-mapper.ts
    ```

  - 4c. Select the appropriate <b>[mapper skeleton](#skeleton)</b> for your export type. Place them in the file created in step 4b. Replace names (<i>skeleton</i> by default) as necessary.

  - 4d. Export your mapper class created in the previous steps by specifying its export in the <i>index.ts</i> file. Add the following line:

    ```
    export * from './src/{YOUR-EXPORT-NAME-HERE}-mapper';
    ```

  - 4e. Create a new directory named <i>{YOUR-EXPORT-NAME-HERE}_mapper</i> under the <i>sample_jsons</i> directory in <i>hdf-converters</i>. Create another directory named <i>sample_input_report</i> in the directory you just made. The file structure should look like this:

    ```
    +-- sample_jsons
    |   +-- {YOUR-EXPORT-NAME-HERE}-mapper
    |   |   +-- sample_input_report
    ```

  - 4f. Place your sample export under the <i>sample_input_report</i> directory. Your sample export should be genericized to avoid any leaking of sensitive information. The file structure should now look like this:

    ```
    +-- sample_jsons
    |   +-- {YOUR-EXPORT-NAME-HERE}-mapper
    |   |   +-- sample_input_report
    |   |   |   +-- {YOUR-SAMPLE-EXPORT}
    ```

  - 4g. Create a blank TypeScript file under the <i>test/mappers/forward</i> directory in <i>hdf-converters</i>. It should be named:

    ```
    {YOUR-EXPORT-NAME-HERE}_mapper.spec.ts
    ```

  - 4h. Select the appropriate <b>[mapper testing skeleton](#skeleton)</b> for your export type. Place it in the file created in step 4g. Replace names (<i>skeleton</i> by default) as necessary.

5. Add fingerprinting to identify your security service scan export.

  - 5a. Go to the file <i>report_intake.ts</i> under the <i>heimdall2/apps/frontend/src/store</i> directory.

  - 5b. Import your mapper file. You should be able to add the name of your mapper class to a pre-existing import statement pointing at <i>hdf-converters</i> as follows:

    ```
    import {
      ASFFResults as ASFFResultsMapper,
      BurpSuiteMapper,
      ...
      {YOUR-MAPPER-CLASS-HERE}
    } from '@mitre/hdf-converters';
    ```

  - 5c. Instantiate your mapper class in the <i>convertToHdf</i> switch block. Add the following lines:

    ```
    case '{YOUR-EXPORT-SERVICE-NAME-HERE}':
      return new {YOUR-MAPPER-CLASS-HERE}(convertOptions.data).toHdf();
    ```

  - 5d. Navigate to the file <i>fingerprinting.ts</i> in the <i>src/utils</i> directory in <i>hdf-converters</i>. Add keywords that are unique to your sample export to the <i>fileTypeFingerprints</i> variable. It should be formatted as follows:

    ```
    export const fileTypeFingerprints = {
      asff: ['Findings', 'AwsAccountId', 'ProductArn'],
      ...
      {YOUR-EXPORT-SERVICE-NAME-HERE}: [{UNIQUE KEYWORDS AS STRINGS}]
    };
    ```

6. Create the \*-to-HDF mapper.

  - 6a. Return to the <i>{YOUR-EXPORT-NAME-HERE}-mapper.ts</i> file. In the file, you should have a generic skeleton mapper picked according to your export type.

  - 6b. Certain security services produce exports which are not immediately usable by the skeleton mapper. In this case, pre-processing on the export and post-processing on the generated HDF file is necessary in order to ensure compatibility.

  - 6c. The skeleton mapper and <b>[<i>base-converter</i>](#base)</b> have been designed to provide the base functionality needed for \*-to-HDF mapper generation. For most developers, mapper creation will be limited to assigning objects from the export structure to correlating attributes in the mapper according to the HDF schema.
    
    - An example of this process is provided in the <b>[\*-to-HDF Mapper Construction Example](#example2)</b> section.

  - 6d. [Commit your changes](https://github.com/git-guides/git-commit) with the [signoff option](https://git-scm.com/docs/git-commit) and [push the changes](https://github.com/git-guides/git-push) to your development branch. This should queue up the Github Actions pipeline which includes a Netlify instance of Heimdall2 which you can use to test if your mapper is generating a HDF file correctly.

7. Set up and use regression testing on your mapper.

  - 7a. Uncomment out the commented out lines in the <i>{YOUR-SAMPLE-EXPORT}-hdf.json</i> file created in step 4f. This will allow the regression tests to automatically generate a HDF output file whenever you run the tests. The commented out lines should look similar to the following:

    ```
    // fs.writeFileSync(
    //   'sample_jsons/skeleton_mapper/skeleton-hdf.json',
    //   JSON.stringify(mapper.toHdf(), null, 2)
    // );
    ```

  - 7b. Using the terminal, cd into the <i>hdf-converters</i> directory and run the following command. This command will run your mapper against the sample export file in <i>sample_jsons</i> and test to see if the output is generated as expected.

    ```
    yarn run test --verbose --silent=false ./test/mappers/forward/{YOUR-EXPORT-NAME-HERE}_mapper.spec.ts
    ```
  
  - 7c. Your tests should generate HDF output files for when <i>--with-raw</i> is not flagged (default behavior) and when it is flagged (denoted by <i>-withraw</i> in the filename). It will also compare the contents of these generated files with a temporary mapper instance created in the test itself. Review the test output to ensure that the tests are all passing and review the HDF output files to ensure that the contents of the mapping are being generated correctly.

  - 7d. Recomment out the lines from step 7b.

8. Document your new mapper in the README for <i>hdf-converters</i> under the <i>Supported Formats</i> section. It should be formatted as follows:

```
{#}. [{YOUR-EXPORT-NAME-HERE}] - {MAPPER INPUT DESCRIPTION}
```

9. Commit your final changes and mark your pull request as 'ready for review'. You should request for a code review from members of the SAF team and edit your code as necessary. Once approved, your mapper will be merged into the main development branch and [scheduled for release](https://github.com/mitre/heimdall2/wiki/How-to-create-a-Heimdall2-release) as an officially supported conversion format for the HDF Converters.

10. Create a development branch against the [SAF CLI repository](https://github.com/mitre/saf) and create a draft pull request for your new branch.

11. Set up for SAF CLI mapper integration.
  
  - 11a. In the <i>package.json</i> file, update the versions of <i>@mitre/hdf-converters</i> and <i>@mitre/heimdall-lite</i> to the [latest release of Heimdall2](https://github.com/mitre/heimdall2/releases).

  - 11b. In the <i>src/commands/convert</i> directory, create a blank TypeScript file. It should be named:

    ```
    {YOUR-EXPORT-NAME-HERE}2hdf.ts
    ```

  - 11c. In the <i>test/sample_data</i> directory, create a directory named <i>{YOUR-EXPORT-NAME-HERE}</i>. Underneath it, create a directory named <i>sample_input_report</i>. The file structure should now look like this:

    ```
    +-- sample_data
    |   +-- {YOUR-EXPORT-NAME-HERE}
    |   |   +-- sample_input_report
    ```

  - 11d. Place your sample export under the <i>sample_input_report</i> directory. Your sample export should be genericized to avoid any leaking of sensitive information. Under the <i>{YOUR-EXPORT-NAME-HERE}</i> directory, place your output HDF files generated during the testing phase of step 7c. The file structure should now look like this:

    ```
    +-- sample_data
    |   +-- {YOUR-EXPORT-NAME-HERE}
    |   |   +-- sample_input_report
    |   |   |   +-- {YOUR-SAMPLE-EXPORT}
    |   |   +-- {YOUR-EXPORT-NAME-HERE}-hdf.json
    |   |   +-- {YOUR-EXPORT-NAME-HERE}-hdf-withraw.json
    ```

  - 11e. In the <i>test/commands/convert</i> directory, create a blank TypeScript file. It should be named:

    ```
    {YOUR-EXPORT-NAME-HERE}2hdf.test.ts
    ```

12. Integrate your mapper with the SAF CLI.

  - 12a. Insert the <b>[skeleton](#skeleton)</b> for integrating a HDF mapper with the SAF CLI. Replace names (<i>skeleton</i> by default) as necessary.

  - 12b. Insert the <b>[skeleton](#skeleton)</b> for a convert command test for the SAF CLI. Replace names (<i>skeleton</i> by default) as necessary.

  - 12c. Navigate to the <i>index.ts</i> file under the <i>src/commands/convert</i> directory. Import your mapper using the existing import block as follows:
  
    ```
    import {
      ASFFResults,
      ...
      {YOUR-MAPPER-CLASS-HERE}
      } from '@mitre/hdf-converters'
    ```
  
  - 12d. Under the switch block in the <i>getFlagsForInputFile</i> function, add your mapper class as it is defined in step 5d for fingerprinting for the generic convert command. If the convert command for your mapper has any additional flags beyond the standard <i>--input</i> and <i>--output</i> flags, return the entire flag block in the switch case. This is demonstrated as follows:
  
    ```
    switch (Convert.detectedType) {
      ...
      case {YOUR-EXPORT-SERVICE-NAME-HERE}:
        return {YOUR-CLI-CONVERT-CLASS}.flags  //Only add if special flags exist
      ...
        return {}
      }
    ```

13. Edit the README file to reflect your newly added conversion command under the <i>To HDF</i> section. It should be formatted as follows:

```
##### {YOUR-EXPORT-NAME-HERE} to HDF

\```
convert {YOUR-EXPORT-NAME-HERE}2hdf       Translate a {YOUR-EXPORT-NAME-HERE} results {EXPORT-TYPE} into
                                              a Heimdall Data Format JSON file

OPTIONS
  -i, --input=input          Input {EXPORT-TYPE} File
  -o, --output=output        Output HDF JSON File
  -w, --with-raw             Include raw input file in HDF JSON file

EXAMPLES
  saf convert {YOUR-EXPORT-NAME-HERE}2hdf -i {INPUT-NAME} -o output-hdf-name.json
\```
```

14. Commit your changes and mark your pull request as 'ready for review'. You should request for a code review from members of the SAF team and edit your code as necessary. Once approved, merged, and [released](https://github.com/mitre/saf/wiki/Creating-a-Release-of-the-SAF-CLI), your mapper will be callable using the SAF CLI.
